{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udcf0 Fake News Detection using NLP and Machine Learning\n", "\n", "**Objective**: Build a model that can classify news articles as *fake* or *real* using NLP techniques and supervised learning.\n", "\n", "**Tools Used**: Python, Pandas, NLTK, Scikit-learn, XGBoost\n", "\n", "Dataset: [Kaggle Fake and Real News Dataset](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import string\n", "import re\n", "import pickle\n", "import nltk\n", "\n", "from nltk.corpus import stopwords\n", "from nltk.stem import WordNetLemmatizer\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n", "from xgboost import XGBClassifier\n", "\n", "nltk.download('stopwords')\n", "nltk.download('wordnet')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fake = pd.read_csv(\"Fake.csv\")\n", "real = pd.read_csv(\"True.csv\")\n", "\n", "fake['label'] = 0\n", "real['label'] = 1\n", "\n", "data = pd.concat([fake, real]).sample(frac=1).reset_index(drop=True)\n", "data = data[['text', 'label']]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stop_words = set(stopwords.words('english'))\n", "lemmatizer = WordNetLemmatizer()\n", "\n", "def clean_text(text):\n", "    text = text.lower()\n", "    text = re.sub(r\"http\\S+\", \"\", text)\n", "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n", "    tokens = text.split()\n", "    filtered = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n", "    return ' '.join(filtered)\n", "\n", "data['cleaned_text'] = data['text'].apply(clean_text)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n", "X = tfidf.fit_transform(data['cleaned_text'])\n", "y = data['label'].values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "\n", "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n", "model.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = model.predict(X_test)\n", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n", "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with open(\"model/model.pkl\", \"wb\") as f:\n", "    pickle.dump(model, f)\n", "\n", "with open(\"model/tfidf_vectorizer.pkl\", \"wb\") as f:\n", "    pickle.dump(tfidf, f)\n", "\n", "print(\"\u2705 Model and vectorizer saved.\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}